{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "hallinc-synapse"
		},
		"HallincCosmosDB_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'HallincCosmosDB'"
		},
		"hallinc-synapse-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'hallinc-synapse-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:hallinc-synapse.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"Sql Serverless_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "hallinc-synapse-ondemand.sql.azuresynapse.net"
		},
		"Sql Serverless_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "Sales"
		},
		"hallinc-synapse-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://hallincdatalake.dfs.core.windows.net"
		},
		"world_wide_importers_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "hallinc-sql-server.database.windows.net"
		},
		"world_wide_importers_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "WWIDB"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Sales_Accessories')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "hallinc-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "raw/sales/special_orders/accessories",
						"fileSystem": "hallinc"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/hallinc-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/HallincCosmosDB')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Cosmos DB database",
				"annotations": [],
				"type": "CosmosDb",
				"typeProperties": {
					"connectionString": "[parameters('HallincCosmosDB_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Sql Serverless')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"server": "[parameters('Sql Serverless_properties_typeProperties_server')]",
					"database": "[parameters('Sql Serverless_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": false,
					"authenticationType": "SystemAssignedManagedIdentity"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/hallinc-synapse-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('hallinc-synapse-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/hallinc-synapse-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('hallinc-synapse-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/hallinc_powerbi')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "e7edf518-d553-4d92-abf7-9c2e4595fba5",
					"tenantID": "375f0d00-5d9c-4f6b-9e6c-1f83fe706392"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/world_wide_importers')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"server": "[parameters('world_wide_importers_properties_typeProperties_server')]",
					"database": "[parameters('world_wide_importers_properties_typeProperties_database')]",
					"encrypt": "mandatory",
					"trustServerCertificate": false,
					"authenticationType": "SystemAssignedManagedIdentity"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				},
				"managedVirtualNetwork": {
					"type": "ManagedVirtualNetworkReference",
					"referenceName": "default"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks",
			"apiVersion": "2019-06-01-preview",
			"properties": {},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DW-test-script')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "-- Items sold by Fiscal Year and Quarter\nSELECT  d.FiscalYear AS FY,\n        d.FiscalQuarter AS FQ,\n        SUM(r.OrderQuantity) AS ItemsSold\nFROM FactResellerSales AS r\nJOIN DimDate AS d ON r.OrderDateKey = d.DateKey\nGROUP BY d.FiscalYear, d.FiscalQuarter\nORDER BY FY, FQ;\n\n-- Items sold by Fiscal Year, Quarter, and sales territory region\nSELECT  d.FiscalYear AS FY,\n        d.FiscalQuarter AS FQ,\n        t. SalesTerritoryRegion AS SalesTerritory,\n        SUM(r.OrderQuantity) AS ItemsSold\nFROM FactResellerSales AS r\nJOIN DimDate AS d ON r.OrderDateKey = d.DateKey\nJOIN DimEmployee AS e ON r.EmployeeKey = e.EmployeeKey\nJOIN DimSalesTerritory AS t ON e.SalesTerritoryKey = t.SalesTerritoryKey\nGROUP BY d.FiscalYear, d.FiscalQuarter, t. SalesTerritoryRegion\nORDER BY FY, FQ, SalesTerritory\n\n\n-- Items sold by Fiscal Year, Quarter, sales territory region, and product category\nSELECT  d.FiscalYear AS FY,\n        d.FiscalQuarter AS FQ,\n        t. SalesTerritoryRegion AS SalesTerritory,\n        pc.EnglishProductCategoryName AS ProductCategory,\n        SUM(r.OrderQuantity) AS ItemsSold\nFROM FactResellerSales AS r\nJOIN DimDate AS d ON r.OrderDateKey = d.DateKey\nJOIN DimEmployee AS e ON r.EmployeeKey = e.EmployeeKey\nJOIN DimSalesTerritory AS t ON e.SalesTerritoryKey = t.SalesTerritoryKey\nJOIN DimProduct AS p ON r.ProductKey = p.ProductKey\nJOIN DimProductSubcategory AS ps ON p.ProductSubcategoryKey = ps.ProductSubcategoryKey\nJOIN DimProductCategory AS pc ON ps.ProductCategoryKey = pc.ProductCategoryKey\nGROUP BY d.FiscalYear, d.FiscalQuarter, t. SalesTerritoryRegion, pc.EnglishProductCategoryName\nORDER BY FY, FQ, SalesTerritory, ProductCategory\n\n\n-- Ranked sales territories by year based on total sales amount\nSELECT  d.FiscalYear,\n        t. SalesTerritoryRegion AS SalesTerritory,\n        SUM(s.SalesAmount) AS TerritoryTotal,\n        SUM(SUM(s.SalesAmount)) OVER(PARTITION BY d.FiscalYear) AS YearTotal,\n        RANK() OVER(PARTITION BY d.FiscalYear\n                    ORDER BY SUM(s.SalesAmount) DESC) AS RankForYear\nFROM FactResellerSales AS s\nJOIN DimDate AS d ON s.OrderDateKey = d.DateKey\nJOIN DimEmployee AS e ON s.EmployeeKey = e.EmployeeKey\nJOIN DimSalesTerritory AS t ON e.SalesTerritoryKey = t.SalesTerritoryKey\nGROUP BY d.FiscalYear, t.SalesTerritoryRegion\nORDER BY d.FiscalYear;\n\n\n-- Approximate number of sales orders per fiscal year by territory\nSELECT  d.FiscalYear,\n        t. SalesTerritoryRegion AS SalesTerritory,\n        APPROX_COUNT_DISTINCT(s.SalesOrderNumber) AS ApproxOrders\nFROM FactResellerSales AS s\nJOIN DimDate AS d ON s.OrderDateKey = d.DateKey\nJOIN DimEmployee AS e ON s.EmployeeKey = e.EmployeeKey\nJOIN DimSalesTerritory AS t ON e.SalesTerritoryKey = t.SalesTerritoryKey\nGROUP BY d.FiscalYear, t.SalesTerritoryRegion\nORDER BY d.FiscalYear, ApproxOrders;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "hallincDW",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/cetas_procedure')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "CREATE PROCEDURE usp_accessories \n    @order_year INT\nAS\nBEGIN\n\n    -- drop table if exists\n    IF EXISTS (\n        SELECT * FROM sys.external_tables\n        WHERE name = 'Accessories'\n    ) \n    DROP EXTERNAL TABLE Accessories\n\n    -- Create external table with orderlinenumber\n\t-- from specified year\n\tCREATE EXTERNAL TABLE Accessories\n\t\tWITH (\n\t\t\tLOCATION = 'special_orders/accessories',\n\t\t\tDATA_SOURCE = sales_files,\n\t\t\tFILE_FORMAT = ParquetFormat\n\t\t)\n\tAS\n\tSELECT SalesOrderNumber, CustomerName, Quantity\n\tFROM\n\t\tOPENROWSET(\n            BULK '*.csv',\n            DATA_SOURCE = 'sales_data',\n            FORMAT = 'CSV',\n            PARSER_VERSION = '2.0',\n            HEADER_ROW = TRUE\n\t\t) AS source_data\n\tWHERE SalesOrderLineNumber = 3\n\tAND YEAR(OrderDate) = @order_year\nEND\n\n-- execute procedure\nEXEC usp_accessories 2021;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "Sales",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/cetas_sales')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "USE Sales;\n\nSELECT name, location FROM sys.external_data_sources;\n\n-- query datasource\nSELECT *\nFROM\n    OPENROWSET(\n        BULK '*.csv',\n        DATA_SOURCE = 'sales_data',\n        FORMAT = 'csv',\n        PARSER_VERSION = '2.0',\n        HEADER_ROW = TRUE\n    ) AS orders\nWHERE \n    SalesOrderLineNumber = 3\n    AND YEAR(OrderDate) = 2021\n;\n\n-- CETAS\nCREATE EXTERNAL TABLE Accessories\n    WITH (\n        -- details for storing results\n        LOCATION = 'special_orders/',\n        DATA_SOURCE = sales_files,\n        FILE_FORMAT = ParquetFormat\n    )\nAS\nSELECT SalesOrderNumber, CustomerName, Quantity\nFROM\n    OPENROWSET(\n        -- details for reading source files\n        BULK '*.csv',\n        DATA_SOURCE = 'sales_data',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        HEADER_ROW = TRUE\n    ) AS source_data\nWHERE SalesOrderLineNumber = 3;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "Sales",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/create_external_table')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": " -- Database for sales data\n CREATE DATABASE Sales\n   COLLATE Latin1_General_100_BIN2_UTF8;\n GO;\n\n Use Sales;\n GO;\n\n  -- create external data source\n CREATE EXTERNAL DATA SOURCE sales_data WITH (\n     LOCATION = 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/sales/csv/'\n );\n GO;\n\n  -- create external data destination\n CREATE EXTERNAL DATA SOURCE sales_files WITH (\n     LOCATION = 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/sales/'\n );\n GO;\n\n  -- Format for table files\n CREATE EXTERNAL FILE FORMAT ParquetFormat\n     WITH (\n             FORMAT_TYPE = PARQUET,\n             DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n         );\n GO;\n\n-- query external data\n SELECT Item AS Product,\n        SUM(Quantity) AS ItemsSold,\n        ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue\n FROM\n     OPENROWSET(\n         BULK '/*.csv',\n         DATA_SOURCE = 'sales_data',\n         FORMAT = 'CSV',\n         PARSER_VERSION = '2.0',\n         HEADER_ROW = TRUE\n     ) AS orders\n GROUP BY Item;\n GO;\n\n-- create external table\nCREATE EXTERNAL TABLE ProductSalesTotals\n     WITH (\n         LOCATION = 'ProductTotals/',\n         DATA_SOURCE = sales_files,\n         FILE_FORMAT = ParquetFormat -- output data format (external file format)\n     )\n AS\n SELECT Item AS Product,\n     SUM(Quantity) AS ItemsSold,\n     ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue\n FROM\n     OPENROWSET(\n         BULK '/*.csv',\n         DATA_SOURCE = 'sales_data', -- prefixed by external data source path\n         FORMAT = 'CSV',\n         PARSER_VERSION = '2.0',\n         HEADER_ROW = TRUE\n     ) AS orders\n GROUP BY Item;\n\n-- DROP EXTERNAL TABLE ProductSalesTotals;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "Sales",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/create_procedure_cetas')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "USE Sales;\nGO;\n\nCREATE PROCEDURE sp_GetYearlySales\nAS\n    BEGIN\n     -- drop existing table\n    IF EXISTS (\n        SELECT * FROM sys.external_tables\n        WHERE name = 'YearlySalesTotals'\n    )\n    DROP EXTERNAL TABLE YearlySalesTotals\n    \n    -- create external table\n    CREATE EXTERNAL TABLE YearlySalesTotals\n    WITH (\n        LOCATION = 'YearlySales/',\n        DATA_SOURCE = sales_files,\n        FILE_FORMAT = ParquetFormat\n    )\n    AS\n        SELECT \n            YEAR(OrderDate) AS CalendarYear,\n            SUM(Quantity) AS ItemsSold,\n            ROUND(SUM(UnitPrice) - SUM(TaxAmount), 2) AS NetRevenue\n        FROM\n            OPENROWSET(\n                BULK '/*.csv',\n                DATA_SOURCE = 'sales_data',\n                FORMAT = 'CSV',\n                PARSER_VERSION = '2.0',\n                HEADER_ROW = TRUE\n         ) AS orders\n     GROUP BY YEAR(OrderDate)\nEND\n\n-- run the procedure\nEXEC sp_GetYearlySales;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "Sales",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/create_staging_table')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "CREATE TABLE dbo.StageProduct\n(\n    ProductID NVARCHAR(10) NOT NULL,\n    ProductName NVARCHAR(200) NOT NULL,\n    ProductCategory NVARCHAR(200) NOT NULL,\n    ListPrice DECIMAL NOT NULL\n)\nWITH\n(\n    DISTRIBUTION = ROUND_ROBIN,\n    CLUSTERED COLUMNSTORE INDEX\n);\nGO\n\nALTER TABLE dbo.DimProduct\nALTER COLUMN ListPrice NVARCHAR(10)\n;\nGO\n\nALTER TABLE dbo.DimProduct\nADD \n    Color VARCHAR (50),\n    Size VARCHAR (50),\n    Discontinued VARCHAR (50);\nGO\n\nALTER TABLE dbo.DimProduct\nALTER COLUMN ProductCategory VARCHAR(50) NULL;\nGO\n\nGO\n-- DROP TABLE dbo.StageProduct;\n\n-- Copy into staging table\nCOPY INTO dbo.StageProduct\n    (ProductID, ProductName, ProductCategory, ListPrice)\nFROM 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/products/products.csv'\nWITH\n(\n    FILE_TYPE = 'CSV',\n    MAXERRORS = 0,\n    IDENTITY_INSERT = 'OFF'\n);\nGO\n\n  -- parquet format for input table files\n CREATE EXTERNAL FILE FORMAT ParquetFormat\n    WITH (\n        FORMAT_TYPE = PARQUET,\n        DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n    );\n GO\n\n--csv format for input table files\nCREATE EXTERNAL FILE FORMAT CsvFormat\nWITH (\n    FORMAT_TYPE = DELIMITEDTEXT,\n    FORMAT_OPTIONS (\n        FIELD_TERMINATOR = ',',\n        STRING_DELIMITER = '\"',\n        FIRST_ROW = 2\n    )\n);\n\n--create external datasource for products\nCREATE EXTERNAL DATA SOURCE products\nWITH (\n    LOCATION = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/csv/products'\n);\n\nGO\n\n--create external table for as staging table\nCREATE EXTERNAL TABLE dbo.ExternalStageProduct\n (\n     ProductID NVARCHAR(10) NOT NULL,\n    ProductName NVARCHAR(200) NOT NULL,\n    ProductCategory NVARCHAR(200) NOT NULL,\n    ListPrice NVARCHAR(10) NOT NULL\n )\nWITH\n (\n    LOCATION = 'products.csv', --needs full file path\n    DATA_SOURCE = products,\n    FILE_FORMAT = CsvFormat\n );\nGO\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "hallincDW",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/database_permissions')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "use master\nCREATE LOGIN [kai@hallinc.onmicrosoft.com] FROM EXTERNAL PROVIDER;\n\nuse Sales -- chosen DB name\nCREATE USER kai FROM LOGIN [kai@hallinc.onmicrosoft.com];\n\nuse Sales -- Use your DB name\nalter role db_datareader \nAdd member kai\n\n\nCREATE LOGIN [kai@hallinc.onmicrosoft.com] FROM EXTERNAL PROVIDER;\nALTER SERVER ROLE sysadmin ADD MEMBER [kai@hallinc.onmicrosoft.com];",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "Sales",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/external_table')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "CREATE EXTERNAL FILE FORMAT CsvFormat\n    WITH (\n        FORMAT_TYPE = DELIMITEDTEXT,\n        FORMAT_OPTIONS(\n            FIELD_TERMINATOR = ',',\n            STRING_DELIMITER = '\"'\n        )\n    );\nGO\n\nCREATE EXTERNAL DATA SOURCE flightsCSV\nWITH (\n    LOCATION = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/flights/'\n);\n\n\n--create external table\nCREATE EXTERNAL TABLE dbo.flights\n(\n    Year INT,\n    Month VARCHAR,\n    DayofMonth VARCHAR,\n    DayOfWeek VARCHAR,\n    Carrier VARCHAR,\n    OriginAirportID VARCHAR,\n    OriginAirportName VARCHAR,\n    OriginCity VARCHAR,\n    OriginState VARCHAR,\n    DestAirportID VARCHAR,\n    DestAirportName VARCHAR,\n    DestCity VARCHAR,\n    DestState VARCHAR,\n    CRSDepTime VARCHAR,\n    DepDelay VARCHAR,\n    DepDel15 VARCHAR,\n    CRSArrTime VARCHAR,\n    ArrDelay VARCHAR,\n    ArrDel15 VARCHAR,\n    Cancelled VARCHAR\n)\nWITH\n(\n    LOCATION = '*.csv',\n    DATA_SOURCE = flightsCSV,\n    FILE_FORMAT = CsvFormat\n);\nGO\n\n-- query the table\nSELECT * FROM dbo.flights;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "FlightDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/openrow_ext_datasource')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "CREATE EXTERNAL DATA SOURCE flights\nWITH (\n    LOCATION = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/flights/parquet/'\n);\n\nSELECT *\nFROM\n    OPENROWSET(\n        BULK 'Year=2013/Month=*/DayofMonth=*/*.parquet',\n        DATA_SOURCE = 'flights',\n        FORMAT = 'parquet'  \n    ) AS flights\nWHERE \n    flights.filepath(1) = '10'\n;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "FlightDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/openrow_json')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT doc\nFROM\n    OPENROWSET(\n        BULK 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/products/*.json',\n        FORMAT = 'csv',\n        FIELDTERMINATOR ='0x0b',\n        FIELDQUOTE = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    ) WITH (doc NVARCHAR(MAX)) as rows",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/openrow_json_value')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT JSON_VALUE(doc, '$.product_name') AS product,\n           JSON_VALUE(doc, '$.list_price') AS price\nFROM\n    OPENROWSET(\n        BULK 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/products/*.json',\n        FORMAT = 'csv',\n        FIELDTERMINATOR ='0x0b',\n        FIELDQUOTE = '0x0b',\n        ROWTERMINATOR = '0x0b'\n    ) WITH (doc NVARCHAR(MAX)) as rows",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "MyBase",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/openrow_partition')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT\n    Carrier,\n    COUNT(CAST(DepDelay AS INT)) AS Delay,\n    SUM(CAST(DepDel15 AS INT)) AS Delay15\n\nFROM OPENROWSET(\n    BULK 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/flights/parquet/Year=*/Month=*/DayofMonth=*/*.parquet',\n    FORMAT = 'parquet'\n    ) AS flights\nWHERE \n    flights.filepath(1) = '2013' AND \n    flights.filepath(2) = '5' AND\n    flights.filepath(3) = '19'\nGROUP BY Carrier\n;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "MyBase",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/openrow_with_dtypes')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT TOP 100 *\nFROM OPENROWSET(\n    BULK 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/products/products2.csv',\n    FORMAT = 'csv',\n    PARSER_VERSION = '2.0')\nWITH (\n    product_id INT,\n    product_name VARCHAR(20) COLLATE Latin1_General_100_BIN2_UTF8,\n    list_price DECIMAL(5,2)\n) AS rows\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "MyBase",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/query_cosmos_sql-serverless')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "--query with created credential\n\nSELECT *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=hallinc-cosmos;Database=HallincCosmosDB',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'hallinc-cosmos'\n) \nWITH \n(\n    OrderID VARCHAR(10) '$.id',\n    OrderDate VARCHAR(10) '$.orderdate',\n    CustomerID INTEGER '$.customerid',\n    CustomerName VARCHAR(40) '$.customerdetails.customername',\n    CustomerEmail VARCHAR(30) '$.customerdetails.customeremail',\n    Product VARCHAR(30) '$.product',\n    Quantity INTEGER '$.quantity',\n    Price FLOAT '$.price'\n)\nAS products_data",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/query_lake_database')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": " SELECT \n    o.SalesOrderID,\n    c.EmailAddress,\n    p.ProductName,\n    o.Quantity\n FROM \n    SalesOrder AS o\n JOIN \n    Customer AS c ON o.CustomerId = c.CustomerId\n JOIN \n    Product AS p ON o.ProductId = p.ProductId;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "retaildb",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/read_json_stream')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "-- This is auto-generated code\nSELECT TOP 100\n    jsonContent\n/* --> place the keys that you see in JSON documents in the WITH clause:\n       , JSON_VALUE (jsonContent, '$.key1') AS header1\n       , JSON_VALUE (jsonContent, '$.key2') AS header2\n*/\nFROM\n    OPENROWSET(\n        BULK 'https://hallincdatalake.dfs.core.windows.net/hallinc/2024/06/28/0_b3690e35163d4567941b2b37badd9e87_1.json',\n        FORMAT = 'CSV',\n        FIELDQUOTE = '0x0b',\n        FIELDTERMINATOR ='0x0b',\n        ROWTERMINATOR = '0x0b'\n    )\n    WITH (\n        jsonContent varchar(MAX)\n    ) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/read_stream_csv')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://hallincdatalake.dfs.core.windows.net/hallinc/2024/**',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0',\n        HEADER_ROW=TRUE\n    ) AS [result]\nORDER BY EndTime;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "default",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql-access-control')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "-- create table\nCREATE TABLE Membership\n(\n    MemberID int IDENTITY,\n    FirstName varchar(100) NULL,\n    SSN char(9) NOT NULL,\n    LastName varchar(100) NOT NULL,\n    Phone varchar(12) NULL,\n    Email varchar(100) NULL\n);\nGO\n\nCREATE LOGIN testuser WITH PASSWORD = '';\nCREATE USER testuser FOR LOGIN [testuser];\n\n--grant select all but sales\nGRANT SELECT ON Membership (MemberID, FirstName, LastName, Phone, Email) TO TestUser;\n\nSELECT * FROM Membership;\n-- Msg 230, Level 14, State 1, Line 1\n-- The SELECT permission was denied on the column 'SSN' of the object 'Membership', database 'hallincDW', schema 'dbo'.\nGO\n\n--row level security\n\n--run in master\nCREATE LOGIN Manager WITH PASSWORD = ''\nGO\nCREATE LOGIN Sales1 WITH PASSWORD = ''\nGO\nCREATE LOGIN Sales2 WITH PASSWORD = ''\nGO\n\n--run in master and your SQL pool database\nCREATE USER Manager FOR LOGIN Manager;  \nCREATE USER Sales1  FOR LOGIN Sales1;  \nCREATE USER Sales2  FOR LOGIN Sales2;\nGO\n\n--create table\nCREATE TABLE Sales  \n(  \n    OrderID int,  \n    SalesRep sysname,  \n    Product varchar(10),  \n    Qty int  \n);\n\nINSERT INTO Sales VALUES (1, 'Sales1', 'Valve', 5);\nINSERT INTO Sales VALUES (2, 'Sales1', 'Wheel', 2);\nINSERT INTO Sales VALUES (3, 'Sales1', 'Valve', 4);\nINSERT INTO Sales VALUES (4, 'Sales2', 'Bracket', 2);\nINSERT INTO Sales VALUES (5, 'Sales2', 'Wheel', 5);\nINSERT INTO Sales VALUES (6, 'Sales2', 'Seat', 5);\n\nSELECT * FROM Sales;\nGO\n\n--create external table\n\nCREATE MASTER KEY ENCRYPTION BY PASSWORD = '';\nCREATE DATABASE SCOPED CREDENTIAL msi_cred WITH IDENTITY = 'Managed Service Identity';\n\n--ext datasource\nCREATE EXTERNAL DATA SOURCE ext_datasource_with_abfss \nWITH \n(\n    TYPE = hadoop, LOCATION = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/external_source/', \n    CREDENTIAL = msi_cred\n);\n\n--external format\nCREATE EXTERNAL FILE FORMAT MSIFormat\nWITH\n(\n    FORMAT_TYPE=DELIMITEDTEXT\n);\n\n--external table\nCREATE EXTERNAL TABLE Sales_ext\nWITH\n(\n    LOCATION='Sales',\n    DATA_SOURCE=ext_datasource_with_abfss,\n    FILE_FORMAT=MSIFormat,\n    REJECT_TYPE=Percentage,\n    REJECT_SAMPLE_VALUE=100,\n    REJECT_VALUE=100\n)\nAS SELECT * FROM sales;\n\n--grant select\nGRANT SELECT ON Sales_ext TO Sales1;  \nGRANT SELECT ON Sales_ext TO Sales2;  \nGRANT SELECT ON Sales_ext TO Manager;\n\n--create schema\nCREATE SCHEMA Security;  \nGO  \n  \nCREATE FUNCTION Security.fn_securitypredicate(@SalesRep AS sysname)  \n    RETURNS TABLE  \nWITH SCHEMABINDING  \nAS  \n    RETURN SELECT 1 AS fn_securitypredicate_result\nWHERE @SalesRep = USER_NAME() OR USER_NAME() = 'Manager';  \nGO\n\n--security policy\nCREATE SECURITY POLICY SalesFilter_ext\nADD FILTER PREDICATE Security.fn_securitypredicate(SalesRep)\nON dbo.Sales_ext  \nWITH (STATE = ON);\n\n\n--clean up\nDROP USER Sales1;\nDROP USER Sales2;\nDROP USER Manager;\n\nDROP SECURITY POLICY SalesFilter_ext;\nDROP TABLE Sales;\nDROP EXTERNAL TABLE Sales_ext;\nDROP EXTERNAL DATA SOURCE ext_datasource_with_abfss ;\nDROP EXTERNAL FILE FORMAT MSIFormat;\nDROP DATABASE SCOPED CREDENTIAL msi_cred; \nDROP MASTER KEY;\n\nDROP LOGIN Sales1;\nDROP LOGIN Sales2;\nDROP LOGIN Manager;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql-ctas')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "CREATE TABLE dbo.DimProduct\nWITH\n(\n    DISTRIBUTION = REPLICATE,\n    CLUSTERED COLUMNSTORE INDEX\n)\nAS\nSELECT ROW_NUMBER() OVER(ORDER BY ProductID) AS ProductKey,\n    ProductID as ProductAltKey,\n    ProductName,\n    ProductCategory,\n    ListPrice\nFROM dbo.StageProduct;\nGO\n\nSELECT * FROM dbo.DimProduct;\n\n--create stg table from git dimproduct\nCREATE EXTERNAL DATA SOURCE [YourExternalDataSource]\nWITH (\n    TYPE = HADOOP,\n    LOCATION = 'https://<your_storage_account>.dfs.core.windows.net/<container>',\n    CREDENTIAL = [YourCredential]\n);\n\nCREATE EXTERNAL FILE FORMAT [YourFileFormat]\nWITH (\n    FORMAT_TYPE = DELIMITEDTEXT,\n    FORMAT_OPTIONS (\n        FIELD_TERMINATOR = ',',\n        STRING_DELIMITER = '\"',\n        FIRST_ROW = 2\n    )\n);\n\nCREATE EXTERNAL TABLE [dbo].[YourExternalTable] (\n    Column1 INT,\n    Column2 NVARCHAR(50),\n    Column3 DATE\n)\nWITH (\n    LOCATION = '/path/to/your/file/',\n    DATA_SOURCE = [YourExternalDataSource],\n    FILE_FORMAT = [YourFileFormat]\n);\n--upsert Dimproduct\n\n\n--rename tables\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "hallincDW",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_load_to_dw')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT * FROM  dbo.StageProduct;\n \nALTER TABLE dbo.StageProduct\nADD \nColor VARCHAR(50),\nSize VARCHAR (50),\nDiscontinued VARCHAR (50);\nGO\n\nALTER TABLE dbo.StageProduct\nALTER COLUMN ProductCategory VARCHAR (50) NULL;\nGO\n\n\n--copy from stage to dim\nCOPY INTO dbo.StageProduct\n    (ProductID, ProductName, ProductCategory, Color, Size, ListPrice, Discontinued)\nFROM 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/products/Product.csv'\nWITH\n(\n    FILE_TYPE = 'CSV',\n    MAXERRORS = 0,\n    IDENTITY_INSERT = 'OFF',\n    FIRSTROW = 2 --Skip header row\n);\nGO\n\n\nSELECT COUNT(1) \nFROM dbo.StageProduct;\nGO\n\n--create staging table for customers\nCREATE TABLE dbo.DimCustomer\n(\n    GeographyKey VARCHAR (50) NOT NULL,\n    CustomerAlternateKey VARCHAR (50) NOT NULL,\n    Title VARCHAR (50),\n    FirstName VARCHAR (50),\n    MiddleName VARCHAR (50),\n    LastName VARCHAR (50),\n    NameStyle VARCHAR (50),\n    BirthDate VARCHAR (50), \n    MaritalStatus VARCHAR (50),\n    Suffix VARCHAR (50),\n    Gender VARCHAR (50),\n    EmailAddress VARCHAR (50),\n    YearlyIncome VARCHAR (50),\n    TotalChildren VARCHAR (50),\n    NumberChildrenAtHome VARCHAR (50),\n    EnglishEducation VARCHAR (50), \n    SpanishEducation VARCHAR (50),\n    FrenchEducation VARCHAR (50),\n    EnglishOccupation VARCHAR (50),\n    SpanishOccupation VARCHAR (50),\n    FrenchOccupation VARCHAR (50),\n    HouseOwnerFlag VARCHAR (50), \n    NumberCarsOwned VARCHAR (50),\n    AddressLine1 VARCHAR (50),\n    AddressLine2 VARCHAR (50),\n    Phone VARCHAR (50),\n    DateFirstPurchase VARCHAR (50),\n    CommuteDistance VARCHAR (50)\n)\nWITH\n(\n    DISTRIBUTION = ROUND_ROBIN,\n    CLUSTERED COLUMNSTORE INDEX\n);\nGO\n\n--populate table with data from file\nCOPY INTO dbo.StageCustomer\n (GeographyKey, CustomerAlternateKey, Title, FirstName, MiddleName, LastName, NameStyle, BirthDate, \n MaritalStatus, Suffix, Gender, EmailAddress, YearlyIncome, TotalChildren, NumberChildrenAtHome, EnglishEducation, \n SpanishEducation, FrenchEducation, EnglishOccupation, SpanishOccupation, FrenchOccupation, HouseOwnerFlag, \n NumberCarsOwned, AddressLine1, AddressLine2, Phone, DateFirstPurchase, CommuteDistance)\n\n FROM 'https://hallincdatalake.dfs.core.windows.net/hallinc/raw/csv/customer/Customer.csv'\n WITH\n (\n    FILE_TYPE = 'CSV',\n    MAXERRORS = 5, \n    FIRSTROW = 2\n);\nGO\n\n--clean dim products\nDROP TABLE dbo.DimProduct;\nGO\n\n--create dimproducts\nCREATE TABLE dbo.DimProduct\n WITH\n (\n     DISTRIBUTION = HASH(ProductAltKey),\n     CLUSTERED COLUMNSTORE INDEX\n )\n AS\n SELECT ROW_NUMBER() OVER(ORDER BY ProductID) AS ProductKey,\n     ProductID AS ProductAltKey,\n     ProductName,\n     ProductCategory,\n     Color,\n     Size,\n     ListPrice,\n     Discontinued\n FROM dbo.StageProduct;\n\n--insert data to dimProduct\nINSERT INTO dbo.DimProduct\n(\n    ProductID,\n    ProductName,\n    ProductCategory,\n    ListPrice,\n    Color,\n    Size,\n    Discontinued\n)\nSELECT \n    ProductID,\n    ProductName,\n    ProductCategory,\n    ListPrice,\n    Color,\n    Size,\n    Discontinued\nFROM dbo.StageProduct;\nGO\n\n--scd customer\n\n--insert\nINSERT INTO dbo.DimCustomer (\n    [GeographyKey],[CustomerAlternateKey],[Title],[FirstName],[MiddleName],[LastName],[NameStyle],[BirthDate],[MaritalStatus],\n    [Suffix],[Gender],[EmailAddress],[YearlyIncome],[TotalChildren],[NumberChildrenAtHome],[EnglishEducation],[SpanishEducation],[FrenchEducation],\n    [EnglishOccupation],[SpanishOccupation],[FrenchOccupation],[HouseOwnerFlag],[NumberCarsOwned],[AddressLine1],[AddressLine2],[Phone],\n    [DateFirstPurchase],[CommuteDistance]\n)\nSELECT *\nFROM dbo.StageCustomer AS stg\nWHERE NOT EXISTS(\n    SELECT * FROM dbo.DimCustomer AS dim\n    WHERE dim.CustomerAlternateKey = stg.CustomerAlternateKey\n);\n\n-- Type 1 updates (change name, email, or phone in place)\n UPDATE dbo.DimCustomer\n SET LastName = stg.LastName,\n     EmailAddress = stg.EmailAddress,\n     Phone = stg.Phone\n FROM DimCustomer dim inner join StageCustomer stg\n ON dim.CustomerAlternateKey = stg.CustomerAlternateKey\n WHERE dim.LastName <> stg.LastName OR dim.EmailAddress <> stg.EmailAddress OR dim.Phone <> stg.Phone\n\n-- Type 2 updates (address changes triggers new entry)\nINSERT INTO dbo.DimCustomer\nSELECT \n    stg.GeographyKey,\n    stg.CustomerAlternateKey,\n    stg.Title,\n    stg.FirstName,\n    stg.MiddleName,\n    stg.LastName,\n    stg.NameStyle,\n    stg.BirthDate,\n    stg.MaritalStatus,\n    stg.Suffix,\n    stg.Gender,\n    stg.EmailAddress,\n    stg.YearlyIncome,\n    stg.TotalChildren,\n    stg.NumberChildrenAtHome,\n    stg.EnglishEducation,\n    stg.SpanishEducation,\n    stg.FrenchEducation,\n    stg.EnglishOccupation,\n    stg.SpanishOccupation,\n    stg.FrenchOccupation,\n    stg.HouseOwnerFlag,\n    stg.NumberCarsOwned,\n    stg.AddressLine1,\n    stg.AddressLine2,\n    stg.Phone,\n    stg.DateFirstPurchase,\n    stg.CommuteDistance\nFROM dbo.StageCustomer AS stg\nJOIN dbo.DimCustomer AS dim\nON stg.CustomerAlternateKey = dim.CustomerAlternateKey\nAND stg.AddressLine1 <> dim.AddressLine1;\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "hallincDW",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_query_cosmos')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "-- working solution\n\n\n--create cred\nCREATE CREDENTIAL cosmosdb\nWITH IDENTITY = 'SHARED ACCESS SIGNATURE',\nSECRET = '';\n\n-- query db\nSELECT *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=hallinc-cosmos;Database=HallincCosmosDB',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'cosmosdb'\n) AS products_data\n\n--select cols with schema\nSELECT *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=hallinc-cosmos;Database=HallincCosmosDB',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'cosmosdb'\n) \nWITH (\n    product VARCHAR(50),\n    price FLOAT\n ) AS products_data\n\n--nested query\nSELECT *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=hallinc-cosmos;Database=HallincCosmosDB',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'cosmosdb'\n) \nWITH (\n    customer VARCHAR (50) '$.customerdetails.customername',\n    product VARCHAR(50) '$.product',\n    price FLOAT '$.price'\n ) AS products_data \n\n\n--create view\n\n--db is needed first\nCREATE DATABASE sales_db\n   COLLATE Latin1_General_100_BIN2_UTF8\nGO;\n \nUSE sales_db;\nGO;\n\nCREATE VIEW products\nAS\nSELECT *\nFROM OPENROWSET(PROVIDER = 'CosmosDB',\n                CONNECTION = 'Account=hallinc-cosmos;Database=HallincCosmosDB',\n                OBJECT = 'Sales',\n                SERVER_CREDENTIAL = 'cosmosdb'\n) \nWITH (\n    customer VARCHAR (50) '$.customerdetails.customername',\n    product VARCHAR(50) '$.product',\n    price FLOAT '$.price'\n ) AS products_data\nGO\n\n-- query the view\nSELECT * FROM products;\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "sales_db",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_read_from_delta')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "SELECT *\nFROM\n    OPENROWSET(\n        BULK 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/orders/',\n        FORMAT = 'DELTA'\n    ) AS deltadata;\n\nCREATE DATABASE StreamDB\n      COLLATE Latin1_General_100_BIN2_UTF8;\nGO;\n\nUSE StreamDB;\nGO\n\nCREATE EXTERNAL DATA SOURCE DeltaLakeStore\nWITH\n(\n    LOCATION = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/'\n);\nGO\n\nSELECT TOP 10 *\nFROM OPENROWSET(\n        BULK '/orders',\n        DATA_SOURCE = 'DeltaLakeStore',\n        FORMAT = 'DELTA'\n    ) as deltadata;\n\n--query catalog tables created in spark\n\nSELECT * FROM managedproducts\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "default",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_synapse_link')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "sql"
				},
				"content": {
					"query": "--create schemas\n\nCREATE SCHEMA Application;\nGO\nCREATE SCHEMA Purchasing;\nGO\nCREATE SCHEMA Sales;\nGO\nCREATE SCHEMA Warehouse;\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "hallincDW",
						"poolName": "hallincDW"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "855144ba-066c-4d5b-a1a3-628af627e4ae"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/csv/products/Product.csv', format='csv', header=True\r\n",
							")\r\n",
							"display(df.schema)"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "fb584311-d502-4564-bc41-b1fae7505ece"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/csv/customer/Customer.csv', format='csv', header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.schema"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Spark Transform')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a17ff56a-4c0f-4777-a499-e43f1bb377da"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Transform data by using Spark\n",
							"\n",
							"This notebook transforms sales order data; converting it from CSV to Parquet format and splitting customer name into two separate fields.\n",
							"\n",
							"## Set variables"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import uuid\r\n",
							"\r\n",
							"# Variable for unique folder name\r\n",
							"folderName = uuid.uuid4()"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Load source data\r\n",
							"\r\n",
							"Let's start by loading some historical sales order data into a dataframe."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"order_details = spark.read.csv('/raw/sales/csv/*.csv', header=True, inferSchema=True)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Transform the data structure\r\n",
							"\r\n",
							"The source data includes a **CustomerName** field, that contains the customer's first and last name. Modify the dataframe to separate this field into separate **FirstName** and **LastName** fields."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from pyspark.sql.functions import split, col\r\n",
							"\r\n",
							"# Create the new FirstName and LastName fields\r\n",
							"transformed_df = order_details.withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)).withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\r\n",
							"\r\n",
							"# Remove the CustomerName field\r\n",
							"transformed_df = transformed_df.drop(\"CustomerName\")"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Save the transformed data\r\n",
							"\r\n",
							"Now save the transformed dataframe in Parquet format in a folder specified in a variable (Overwriting the data if it already exists)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"transformed_df.write.mode(\"overwrite\").parquet('/%s' % folderName)\r\n",
							"print (\"Transformed data saved in %s!\" % folderName)"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/analyze_with_spark')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "078af7d3-8fa5-4a22-822c-6822a5e7e642"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"\r\n",
							"# import with header\r\n",
							"df = spark.read.load('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/csv/products/products.csv',\r\n",
							"    format='csv',\r\n",
							"    header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# write to new container\r\n",
							"df.write \\\r\n",
							"    .format('csv') \\\r\n",
							"    .option('header', 'true') \\\r\n",
							"    .save('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/products/product_data.csv')"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# import with schema\r\n",
							"\r\n",
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"#create schema\r\n",
							"productSchema = StructType([\r\n",
							"    StructField(\"Product_ID\", IntegerType()),\r\n",
							"    StructField(\"Product_Name\", StringType()),\r\n",
							"    StructField(\"Product_Category\", StringType()),\r\n",
							"    StructField(\"List_Price\", FloatType())\r\n",
							"])\r\n",
							"\r\n",
							"# import without header\r\n",
							"df = spark.read.load('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/products/product_data.csv',\r\n",
							"    format='csv',\r\n",
							"    schema=productSchema,\r\n",
							"    header=False)\r\n",
							"display(df.limit(5))"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# select from df\r\n",
							"display(\r\n",
							"    df.select(\"Product_ID\", \"List_Price\").limit(5)\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# chain tarnsformations\r\n",
							"display(\r\n",
							"    df\r\n",
							"    .select(\"Product_Name\", \"List_Price\")\r\n",
							"    .where((df[\"Product_Category\"]==\"Mountain Bikes\") | (df[\"Product_Category\"]==\"Road Bikes\"))\r\n",
							"    .limit(3)\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# group by attribute\r\n",
							"display(\r\n",
							"    df\r\n",
							"    .select('Product_ID', 'Product_Category')\r\n",
							"    .groupBy('Product_Category')\r\n",
							"    .count()\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# create temp view\r\n",
							"df.createOrReplaceTempView(\"products\")\r\n",
							"\r\n",
							"# query temp view\r\n",
							"display(\r\n",
							"    spark.sql(\r\n",
							"        \"SELECT Product_ID, Product_Name, List_Price \\\r\n",
							"        FROM products \\\r\n",
							"        WHERE Product_Category IN ('Mountain Bikes')\"\r\n",
							"    )\r\n",
							"    .limit(3)\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- query temp view with sql\r\n",
							"\r\n",
							"SELECT \r\n",
							"    Product_Category, COUNT(Product_ID) AS Product_Count\r\n",
							"FROM products\r\n",
							"GROUP BY Product_Category\r\n",
							"ORDER BY Product_Category"
						],
						"outputs": [],
						"execution_count": 18
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/insert_into_lake_database')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "9732277f-f36e-4c39-b70a-8c5e04929132"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "sql"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							" INSERT INTO `RetailDB`.`SalesOrder` VALUES (99999, CAST('2022-01-01' AS TimeStamp), 1, 6, 5, 1)"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							" SELECT * FROM `RetailDB`.`SalesOrder` WHERE SalesOrderId = 99999"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/load-and-query-cosmos')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "54a90a7d-c760-4bea-a60d-0f5b7f7fb8a8"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"# in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
							"\n",
							"df = spark.read\\\n",
							"    .format(\"cosmos.olap\")\\\n",
							"    .option(\"spark.synapse.linkedService\", \"HallincCosmosDB\")\\\n",
							"    .option(\"spark.cosmos.container\", \"Sales\")\\\n",
							"    .load()\n",
							"\n",
							"display(df.limit(3))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"customer_df = df.select(\"customerid\", \"customerdetails\")\r\n",
							"display(customer_df)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# unpack customer details column\r\n",
							"customerdetails_df = df.select(\"customerid\", \"customerdetails.*\")\r\n",
							"display(customerdetails_df)"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- Create a logical database in the Spark metastore\r\n",
							"CREATE DATABASE salesdb;\r\n",
							"\r\n",
							"USE salesdb;\r\n",
							"\r\n",
							"-- Create a table from the Cosmos DB container\r\n",
							"CREATE TABLE salesorders using cosmos.olap \r\n",
							"    options (\r\n",
							"    spark.synapse.linkedService 'HallincCosmosDB',\r\n",
							"    spark.cosmos.container 'Sales'\r\n",
							"    );\r\n",
							"\r\n",
							"-- Query the table\r\n",
							"SELECT *\r\n",
							"FROM salesorders;"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"SELECT id, orderdate, customerdetails.customername, product\r\n",
							"FROM salesorders\r\n",
							"ORDER BY id;"
						],
						"outputs": [],
						"execution_count": 5
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/query_cosmos')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "e9394df6-550a-4357-8f3e-ececd658c3cd"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"df = spark.read \\\r\n",
							"    .format(\"cosmos.olap\")\\\r\n",
							"    .option(\"spark.synapse.linkedService\", \"HallincCosmosDB\")\\\r\n",
							"    .option(\"spark.cosmos.container\", \"Sales\")\\\r\n",
							"    .load()\r\n",
							"\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"products_df = df.select(\"customerdetails\",\"product\").orderBy(\"product\")\r\n",
							"display(products_df.limit(10))"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- Create a logical database in the Spark metastore\r\n",
							"CREATE DATABASE mydb;\r\n",
							"\r\n",
							"USE mydb;\r\n",
							"\r\n",
							"-- Create a table from the Cosmos DB container\r\n",
							"CREATE TABLE products using cosmos.olap options (\r\n",
							"    spark.synapse.linkedService 'HallincCosmosDB',\r\n",
							"    spark.cosmos.container 'Sales'\r\n",
							");"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- Query the table\r\n",
							"SELECT customerid, product\r\n",
							"FROM products;"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_analyze_lab')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "edbe68c8-419a-4cfb-8aff-40bbc6281790"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"jupyter": {
								"outputs_hidden": true
							},
							"collapsed": false
						},
						"source": [
							"  %%pyspark\r\n",
							" from pyspark.sql.types import *\r\n",
							" from pyspark.sql.functions import *\r\n",
							"\r\n",
							" schema = StructType([\r\n",
							"     StructField(\"SalesOrderNumber\", StringType()),\r\n",
							"     StructField(\"SalesOrderLineNumber\", IntegerType()),\r\n",
							"     StructField(\"OrderDate\", DateType()),\r\n",
							"     StructField(\"CustomerName\", StringType()),\r\n",
							"     StructField(\"Email\", StringType()),\r\n",
							"     StructField(\"Item\", StringType()),\r\n",
							"     StructField(\"Quantity\", IntegerType()),\r\n",
							"     StructField(\"UnitPrice\", FloatType()),\r\n",
							"     StructField(\"Tax\", FloatType())\r\n",
							"     ])\r\n",
							"\r\n",
							" df = spark.read.load(\r\n",
							"    'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/sales/csv/*.csv',\r\n",
							"    format='csv',\r\n",
							"    schema=schema\r\n",
							" )\r\n",
							" display(df.limit(100))"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.printSchema()"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# analyze customer counts\r\n",
							"customer = df['CustomerName', 'Email']\r\n",
							"print(customer.count())\r\n",
							"print(customer.distinct().count())\r\n",
							"display(customer.distinct())"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# analyze customer count by product\r\n",
							"\r\n",
							"customer = df.select('CustomerName', 'Email').where(df['Item'] =='Road-250 Red, 52')\r\n",
							"print(customer.count())\r\n",
							"print(customer.distinct().count())\r\n",
							"display(customer.distinct())"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# group by item\r\n",
							"productSales = df.select(\"Item\", \"Quantity\").groupBy(\"Item\").sum()\r\n",
							"display(productSales)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"\r\n",
							"yearlySales = df.select(\r\n",
							"    year(\"OrderDate\").alias(\"Year\")) \\\r\n",
							"    .groupBy(\"Year\") \\\r\n",
							"    .count() \\\r\n",
							"    .orderBy(\"Year\")\r\n",
							"display(yearlySales)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# query with spark.sql\r\n",
							"\r\n",
							"# create temp view\r\n",
							"df.createOrReplaceTempView('salesorder')\r\n",
							"\r\n",
							"#query with spark.sql\r\n",
							"sales_df = spark.sql(\"SELECT * FROM salesorder LIMIT 5\")\r\n",
							"display(sales_df)"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- query spark temp view directly with sql\r\n",
							"SELECT \r\n",
							"    YEAR(OrderDate) AS OrderYear,\r\n",
							"    SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue\r\n",
							"FROM salesorder\r\n",
							"GROUP BY YEAR(OrderDate)\r\n",
							"ORDER BY OrderYear;"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"--analyze using charts\r\n",
							" SELECT * FROM salesorder"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# matplotlib\r\n",
							"\r\n",
							"# create query\r\n",
							"sqlQuery = \"SELECT CAST(YEAR(OrderDate) AS CHAR(4)) AS OrderYear, \\\r\n",
							"            SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue \\\r\n",
							"            FROM salesorder \\\r\n",
							"            GROUP BY CAST(YEAR(OrderDate) AS CHAR(4)) \\\r\n",
							"            ORDER BY OrderYear\"\r\n",
							"\r\n",
							"df_spark = spark.sql(sqlQuery).na.drop('all')\r\n",
							"df_spark.show()"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# visualize with plt\r\n",
							"\r\n",
							"from matplotlib import pyplot as plt\r\n",
							"\r\n",
							"# convert to pandas\r\n",
							"df_sales = df_spark.toPandas()\r\n",
							"\r\n",
							"# clear the plot area\r\n",
							"plt.clf()\r\n",
							"\r\n",
							"# create a figure\r\n",
							"fig = plt.figure(figsize=(8,3))\r\n",
							"\r\n",
							"# bar plot of revenue by year\r\n",
							"plt.bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'])\r\n",
							"\r\n",
							"# Customize the chart\r\n",
							"plt.title('Revenue by Year')\r\n",
							"plt.xlabel('Year')\r\n",
							"plt.ylabel('Revenue')\r\n",
							"plt.grid(color='#95a5a6', linestyle='--', linewidth=1, axis='y', alpha=0.4)\r\n",
							"plt.xticks(rotation=45, fontsize=8)\r\n",
							"plt.tight_layout\r\n",
							"plt.show();"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# subplots\r\n",
							"plt.clf()\r\n",
							"\r\n",
							"# Create a figure for 2 subplots (1 row, 2 columns)\r\n",
							"fig, ax = plt.subplots(1, 2, figsize = (10,4))\r\n",
							"\r\n",
							"# Create a bar plot of revenue by year on the first axis\r\n",
							"ax[0].bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'], color='orange')\r\n",
							"ax[0].set_title('Revenue by Year')\r\n",
							"\r\n",
							"# Create a pie chart of yearly order counts on the second axis\r\n",
							"yearly_counts = df_sales['OrderYear'].value_counts()\r\n",
							"ax[1].pie(yearly_counts)\r\n",
							"ax[1].set_title('Orders per Year')\r\n",
							"ax[1].legend(yearly_counts.keys().tolist())\r\n",
							"\r\n",
							"# Add a title to the Figure\r\n",
							"fig.suptitle('Sales Data')\r\n",
							"\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# same with seaborn\r\n",
							"\r\n",
							"import seaborn as sns\r\n",
							"\r\n",
							"# Clear the plot area\r\n",
							"plt.clf()\r\n",
							"\r\n",
							"# Set the visual theme for seaborn\r\n",
							"sns.set_theme(style=\"whitegrid\")\r\n",
							"\r\n",
							"# Create a bar chart\r\n",
							"ax = sns.barplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Clear the plot area\r\n",
							"plt.clf()\r\n",
							"\r\n",
							"# Set the visual theme for seaborn\r\n",
							"sns.set_theme(style=\"whitegrid\")\r\n",
							"\r\n",
							"# Create a line chart\r\n",
							"ax = sns.lineplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 38
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_dataframes')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "6a7fe71f-6249-478d-88be-c363d14154d3"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Transform with Pyspark**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"order_details = spark.read.csv('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/sales/csv/*.csv', header=True, inferSchema=True)\r\n",
							"display(order_details.limit(5))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# split columns\r\n",
							"\r\n",
							"from pyspark.sql.functions import split, col\r\n",
							"\r\n",
							"# Create FirstName and LastName columns\r\n",
							"transformed_df = order_details \\\r\n",
							"    .withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)) \\\r\n",
							"    .withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\r\n",
							"\r\n",
							"# Remove the CustomerName field\r\n",
							"transformed_df = transformed_df.drop(\"CustomerName\")"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# write to parquet\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/parquet/products/orders'\r\n",
							"\r\n",
							"transformed_df.write \\\r\n",
							"    .mode(\"overwrite\") \\\r\n",
							"    .parquet(path)\r\n",
							"print (f\"data saved to {path}.\")"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# add year partitioning\r\n",
							"\r\n",
							"from pyspark.sql.functions import year, col\r\n",
							"\r\n",
							"# Add derived 'Year' column\r\n",
							"dated_df = transformed_df.withColumn(\"Year\", year(col(\"OrderDate\")))\r\n",
							"\r\n",
							"# Partition by year\r\n",
							"dated_df.write \\\r\n",
							"    .partitionBy(\"Year\") \\\r\n",
							"    .mode(\"overwrite\") \\\r\n",
							"    .parquet(path=path)\r\n",
							"    \r\n",
							"[file.name for file in mssparkutils.fs.ls(path)]"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(spark.read.parquet(f'{path}/Year=2020').limit(3))"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"**Transform with pyspark.sql**"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# create persistent external table from original order_details\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/parquet/products/orders_table'\r\n",
							"order_details.write.saveAsTable('sales_orders', format='parquet', mode='overwrite', path=path)"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# transform the table\r\n",
							"\r\n",
							"path='abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/parquet/products/order_table_transformed'\r\n",
							"\r\n",
							"# Create derived columns into existing table\r\n",
							"sql_transform = spark.sql(\r\n",
							"    \"SELECT *, YEAR(OrderDate) AS Year, MONTH(OrderDate) AS Month \\\r\n",
							"    FROM sales_orders\"\r\n",
							")\r\n",
							"\r\n",
							"# Save the results as transformed table\r\n",
							"sql_transform.write \\\r\n",
							"    .partitionBy(\"Year\",\"Month\") \\\r\n",
							"    .saveAsTable(\r\n",
							"        'transformed_orders',\r\n",
							"        format='parquet',\r\n",
							"        mode='overwrite',\r\n",
							"        path=path\r\n",
							"    )"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"[file.name for file in mssparkutils.fs.ls(path)]"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- query table from metastore\r\n",
							"SELECT * FROM transformed_orders\r\n",
							"WHERE Year = 2021\r\n",
							"    AND Month = 1"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"DROP TABLE transformed_orders;\r\n",
							"DROP TABLE sales_orders;"
						],
						"outputs": [],
						"execution_count": 15
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_delta_streaming')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "067b2e65-811c-474f-8b95-49c05efc2de3"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"<h1>spark structured streaming lab</b>"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"<b>Source Stream</b>"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from notebookutils import mssparkutils\r\n",
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"# input destination for streaming data\r\n",
							"input_path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/streaming_data/'\r\n",
							"\r\n",
							"# Create a stream that reads data from the folder, using a JSON schema\r\n",
							"jsonSchema = StructType([\r\n",
							"StructField(\"device\", StringType(), False),\r\n",
							"StructField(\"status\", StringType(), False)\r\n",
							"])\r\n",
							"\r\n",
							"# start the structured stream from input location with json schema\r\n",
							"iotstream = spark.readStream \\\r\n",
							"    .schema(jsonSchema) \\\r\n",
							"    .option(\"maxFilesPerTrigger\", 1) \\\r\n",
							"    .json(input_path)\r\n",
							"\r\n",
							"# Write some event data to the folder\r\n",
							"device_data = '''\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"error\"}\r\n",
							"{\"device\":\"Dev2\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"'''\r\n",
							"# write data into text file with mssparkutils\r\n",
							"mssparkutils.fs.put(input_path + \"data.txt\", device_data, True)\r\n",
							"print(\"Source stream created...\")"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# show the file contents\r\n",
							"print(mssparkutils.fs.head(input_path + 'data.txt'))"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Write the stream to a delta table\r\n",
							"\r\n",
							"# sink table and checkpoint locations\r\n",
							"delta_stream_table_path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/iotdevicetable/'\r\n",
							"checkpointpath = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/checkpoint/'\r\n",
							"\r\n",
							"# stream to sink\r\n",
							"deltastream = iotstream.writeStream \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .option(\"checkpointLocation\", checkpointpath) \\\r\n",
							"    .start(delta_stream_table_path)\r\n",
							"print(\"Streaming to delta sink...\")"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Read the data in delta format into a dataframe\r\n",
							"\r\n",
							"df = spark.read \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .load(delta_stream_table_path)\r\n",
							"display(df.count())"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# create catalog table based on the sink\r\n",
							"\r\n",
							"spark.sql(\"CREATE TABLE IotDeviceData USING DELTA LOCATION '{0}'\".format(delta_stream_table_path))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Add more data to the source stream\r\n",
							"\r\n",
							"more_data = '''\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"error\"}\r\n",
							"{\"device\":\"Dev2\",\"status\":\"error\"}\r\n",
							"{\"device\":\"Dev1\",\"status\":\"ok\"}\r\n",
							"'''\r\n",
							"\r\n",
							"mssparkutils.fs.put(input_path + \"more-data.txt\", more_data, True)"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							" %%sql\r\n",
							"\r\n",
							" SELECT COUNT(*) FROM IotDeviceData;"
						],
						"outputs": [],
						"execution_count": 18
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_delta_tables')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "03029928-73cd-4d18-9ee0-163e41c46489"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 120
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"<b> Delta tables <b>"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Load a file into a dataframe\r\n",
							"df = spark.read.load(\r\n",
							"    'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/products/product_data.csv/*csv',\r\n",
							"    format='csv',\r\n",
							"    header=True\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Save the dataframe as a delta table \r\n",
							"\r\n",
							"delta_table_path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/products'\r\n",
							"\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .mode('overwrite') \\\r\n",
							"    .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# conditional updates\r\n",
							"\r\n",
							"from delta.tables import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"delta_table_path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/products'\r\n",
							"\r\n",
							"# Create a deltaTable object\r\n",
							"deltatable = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"# Update the table (reduce price of accessories by 10%)\r\n",
							"deltatable.update(\r\n",
							"    condition = \"Category == 'Lights'\",\r\n",
							"    set = { \"ListPrice\": \"ListPrice * 0.9\" }\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# query older version \r\n",
							"df = spark \\\r\n",
							"    .read.format(\"delta\") \\\r\n",
							"    .option(\"versionAsOf\", 0) \\\r\n",
							"    .load(delta_table_path)\r\n",
							"\r\n",
							"display(df.filter(df['Category']=='Lights'))"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# query new version \r\n",
							"df = spark \\\r\n",
							"    .read.format(\"delta\") \\\r\n",
							"    .option(\"versionAsOf\", 1) \\\r\n",
							"    .load(delta_table_path)\r\n",
							"\r\n",
							"display(df.filter(df['Category']=='Lights'))"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"<b> Catalog tables <b>"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# create managed and external catalog tables\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/products_external'\r\n",
							"\r\n",
							"# Save a dataframe as a managed table, no path needed\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .saveAsTable(\"products_managed\")\r\n",
							"\r\n",
							"## specify a path option to save as an external table\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .option(\"path\", path) \\\r\n",
							"    .saveAsTable(\"products_external\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(\r\n",
							"    spark.sql('SELECT * FROM products_managed')\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- create table schema\r\n",
							"\r\n",
							"CREATE TABLE ManagedSalesOrders\r\n",
							"(\r\n",
							"    Orderid INT NOT NULL,\r\n",
							"    OrderDate TIMESTAMP NOT NULL,\r\n",
							"    CustomerName STRING,\r\n",
							"    SalesTotal FLOAT NOT NULL\r\n",
							")\r\n",
							"USING DELTA"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"-- query the table\r\n",
							"SELECT orderid, salestotal\r\n",
							"FROM ManagedSalesOrders"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# create catalog table using DeltaTableBuilder\r\n",
							"\r\n",
							"from delta.tables import *\r\n",
							"\r\n",
							"DeltaTable.create(spark) \\\r\n",
							"  .tableName(\"default.ManagedProducts\") \\\r\n",
							"  .addColumn(\"Productid\", \"INT\") \\\r\n",
							"  .addColumn(\"ProductName\", \"STRING\") \\\r\n",
							"  .addColumn(\"Category\", \"STRING\") \\\r\n",
							"  .addColumn(\"Price\", \"FLOAT\") \\\r\n",
							"  .execute()"
						],
						"outputs": [],
						"execution_count": 27
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_delta_tables_streaming')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "d0f5d1a2-2833-4c12-bb18-869f1b8709b1"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"<b> Structured Streaming<b>"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"spark.sql(\"DROP TABLE IF EXISTS orders_stream\")\r\n",
							"\r\n",
							"# create schema\r\n",
							"schema = StructType([\r\n",
							"    StructField('ProductID', StringType(), True),\r\n",
							"    StructField('ProductName', StringType(), True),\r\n",
							"    StructField('Category', StringType(), True),\r\n",
							"    StructField('ListPrice', StringType(), True)\r\n",
							"])\r\n",
							"\r\n",
							"# create empty dataframe\r\n",
							"df = spark.createDataFrame(\r\n",
							"    [],\r\n",
							"    schema=schema\r\n",
							")\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/orders/'\r\n",
							"\r\n",
							"# create empty delta table\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .option(\"path\", path) \\\r\n",
							"    .saveAsTable(\"orders_stream\")"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Load a streaming dataframe from the Delta Table\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/delta/orders/'\r\n",
							"\r\n",
							"stream_df = spark.readStream.format(\"delta\") \\\r\n",
							"    .option(\"ignoreChanges\", \"true\") \\\r\n",
							"    .load(path)\r\n",
							"\r\n",
							"# process the streaming data in the dataframe\r\n",
							"stream_df.writeStream \\\r\n",
							"    .outputMode(\"append\") \\\r\n",
							"    .format(\"console\") \\\r\n",
							"    .start()"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"stream_df.writeStream\\\r\n",
							"    .format(\"memory\")\\\r\n",
							"    .queryName(\"stream_table\")\\\r\n",
							"    .trigger(processingTime='5 seconds')\\\r\n",
							"    .start()\\\r\n",
							"    .awaitTermination(60)"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# append a row\r\n",
							"\r\n",
							"new_row = spark.createDataFrame([\r\n",
							"    Row(\r\n",
							"        ProductID=\"008\",\r\n",
							"        ProductName=\"Product C\",\r\n",
							"        Category=\"Category1\",\r\n",
							"        ListPrice=\"70.00\"\r\n",
							"    )\r\n",
							"])\r\n",
							"df = df.union(new_row)\r\n",
							"\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .mode(\"append\") \\\r\n",
							"    .saveAsTable(\"orders_stream\")\r\n",
							"\r\n",
							"df.write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .mode(\"append\") \\\r\n",
							"    .saveAsTable(\"orders_stream\")"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"SELECT * FROM stream_table;"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# streaming sink\r\n",
							"\r\n",
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/streaming_data/'\r\n",
							"\r\n",
							"# stream that reads JSON data from a folder\r\n",
							"inputPath = path\r\n",
							"jsonSchema = StructType([\r\n",
							"    StructField(\"device\", StringType(), False),\r\n",
							"    StructField(\"status\", StringType(), False)\r\n",
							"])\r\n",
							"stream_df = spark.readStream \\\r\n",
							"    .schema(jsonSchema) \\\r\n",
							"    .option(\"maxFilesPerTrigger\", 1) \\\r\n",
							"    .json(inputPath)\r\n",
							"\r\n",
							"# Write the stream to a delta table\r\n",
							"table_path = '/delta/devicetable'\r\n",
							"checkpoint_path = '/delta/checkpoint'\r\n",
							"delta_stream = stream_df.writeStream \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .option(\"checkpointLocation\", checkpoint_path) \\\r\n",
							"    .start(table_path)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"CREATE TABLE DeviceTable\r\n",
							"USING DELTA\r\n",
							"LOCATION '/delta/devicetable';"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"SELECT *\r\n",
							"FROM DeviceTable;"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"delta_stream.stop()"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark_with_plt')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "1ff27740-c0e4-460b-8a91-59ab6061bce6"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\r\n",
							"\r\n",
							"# import data\r\n",
							"df = spark.read.load('abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/csv/products/products.csv',\r\n",
							"    format='csv',\r\n",
							"    header=True\r\n",
							")\r\n",
							"\r\n",
							"# create temp view\r\n",
							"df.createOrReplaceTempView(\"products\")"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# import plt\r\n",
							"from matplotlib import pyplot as plt\r\n",
							"\r\n",
							"# create pandas frame\r\n",
							"data = spark.sql(\r\n",
							"    \"SELECT Category, COUNT(ProductID) AS ProductCount \\\r\n",
							"    FROM products \\\r\n",
							"    GROUP BY Category \\\r\n",
							"    ORDER BY Category\") \\\r\n",
							"    .toPandas()\r\n",
							"# slice with iloc\r\n",
							"display(\r\n",
							"    data.iloc[0:3, :2]\r\n",
							")"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# create charts with plt\r\n",
							"\r\n",
							"# clear the plot area\r\n",
							"plt.clf()\r\n",
							"\r\n",
							"# create fig\r\n",
							"fig = plt.figure(figsize=(9,6))\r\n",
							"\r\n",
							"# create bar chart\r\n",
							"plt.bar(x=data['Category'], height=data['ProductCount'], color='blue')\r\n",
							"\r\n",
							"# fine tune the chart\r\n",
							"plt.title('Products/Category')\r\n",
							"plt.xlabel('Category')\r\n",
							"plt.ylabel('Products')\r\n",
							"plt.grid(\r\n",
							"    color='#95a5a6',\r\n",
							"    linestyle='--',\r\n",
							"    linewidth=2,\r\n",
							"    axis='y',\r\n",
							"    alpha=0.7\r\n",
							")\r\n",
							"plt.xticks(rotation=70, fontsize=9) # make ticks readable\r\n",
							"plt.tight_layout()\r\n",
							"plt.show();"
						],
						"outputs": [],
						"execution_count": 52
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/write-adsl-partition')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "notebooks"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "hallincspark",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "0d52f16b-8118-44ad-8285-e589f4034823"
					}
				},
				"metadata": {
					"saveOutput": false,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse/bigDataPools/hallincspark",
						"name": "hallincspark",
						"type": "Spark",
						"endpoint": "https://hallinc-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hallincspark",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 10
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load(\r\n",
							"    'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/flights/flights.csv',\r\n",
							"    format='csv',\r\n",
							"    header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.types import StructType\r\n",
							"schema = [i for i in df.schema]\r\n",
							"schema"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# partition df by year, month, day\r\n",
							"\r\n",
							"path = 'abfss://hallinc@hallincdatalake.dfs.core.windows.net/raw/flights/parquet'\r\n",
							"\r\n",
							"# Write DataFrame to ADLS\r\n",
							"df.write.partitionBy('Year', 'Month', 'DayofMonth').parquet(path)"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/retaildb')]",
			"type": "Microsoft.Synapse/workspaces/databases",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"Ddls": [
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "retaildb",
							"EntityType": "DATABASE",
							"Origin": {
								"Type": "SPARK"
							},
							"Properties": {
								"IsSyMSCDMDatabase": true,
								"DerivedModelDBInfo": "{\"ModelDirectives\":{\"BaseModel\":{\"Name\":\"Retail\",\"Version\":\"1.3.0\"}}}"
							},
							"Source": {
								"Provider": "ADLS",
								"Location": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb",
								"Properties": {
									"FormatType": "csv",
									"LinkedServiceName": "hallinc-synapse-WorkspaceDefaultStorage"
								}
							},
							"PublishStatus": "PUBLISHED",
							"ObjectVersion": 4,
							"ObjectId": "c408fd3f-1c80-405e-aef2-bd04cb379f68"
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "customer",
							"EntityType": "TABLE",
							"TableType": "EXTERNAL",
							"Namespace": {
								"SchemaName": null,
								"DatabaseName": "retaildb",
								"DatabaseId": null
							},
							"Partitioning": {
								"PartitionFunctionType": null,
								"Keys": null
							},
							"StorageDescriptor": {
								"Distribution": null,
								"Columns": [
									{
										"Name": "CustomerId",
										"Description": "Unique customer ID",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									},
									{
										"Name": "FirstName",
										"Description": "Customer first name",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 256,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										}
									},
									{
										"Name": "LastName",
										"Description": "Customer last name",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 256,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										}
									},
									{
										"Name": "EmailAddress",
										"Description": "Customer email",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 256,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										}
									},
									{
										"Name": "Phone",
										"Description": "Customer phone",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 256,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										}
									}
								],
								"ColumnSetEntityName": "95431d19-9b4b-4eef-9f9d-91fae21543a9",
								"Format": {
									"InputFormat": "org.apache.hadoop.mapred.SequenceFileInputFormat",
									"OutputFormat": "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat",
									"FormatType": "csv",
									"SerializeLib": "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
									"Properties": {
										"path": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/customer",
										"delimiter": ",",
										"firstRowAsHeader": "false",
										"multiLine": "false",
										"serialization.format": "1",
										"escape": "\\",
										"quote": "\"",
										"FormatTypeSetToDatabaseDefault": true,
										"header": "false"
									}
								},
								"Source": {
									"Provider": "ADLS",
									"Location": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/customer",
									"Properties": {
										"LinkedServiceName": "hallinc-synapse-WorkspaceDefaultStorage",
										"LocationSetToDatabaseDefault": true
									}
								},
								"Properties": {
									"textinputformat.record.delimiter": ",",
									"compression": "{\"type\":\"None\",\"level\":\"optimal\"}",
									"derivedModelAttributeInfo": "{\"attributeReferences\":{}}"
								},
								"Compressed": false,
								"SerDeInfo": null,
								"IsStoredAsSubdirectories": false
							},
							"Owner": null,
							"CreateTime": 0,
							"LastAccessTime": 0,
							"Retention": 0,
							"Temporary": false,
							"IsRewriteEnabled": false,
							"ViewOriginalText": null,
							"ViewExpandedText": null,
							"Origin": {
								"Type": "SPARK"
							},
							"OriginObjectId": null,
							"IsSharedEntity": false,
							"PublishStatus": "PUBLISHED",
							"Properties": {
								"Description": "",
								"DisplayFolderInfo": "{\"name\":\"Others\",\"colorCode\":\"\"}",
								"PrimaryKeys": "CustomerId",
								"spark.sql.sources.provider": "csv",
								"spark.sql.sources.schema.numParts": "1",
								"spark.sql.sources.schema.part.0": "{\"type\":\"struct\",\"fields\":[{\"name\":\"CustomerId\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"FirstName\",\"type\":\"string\",\"nullable\":false,\"metadata\":{}},{\"name\":\"LastName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"EmailAddress\",\"type\":\"string\",\"nullable\":false,\"metadata\":{}},{\"name\":\"Phone\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
							},
							"ObjectVersion": 1,
							"ObjectId": "c83a2827-407d-4fce-8788-0a7ec8a7d9fa",
							"Description": ""
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "product",
							"EntityType": "TABLE",
							"TableType": "EXTERNAL",
							"Namespace": {
								"SchemaName": null,
								"DatabaseName": "retaildb",
								"DatabaseId": null
							},
							"Partitioning": {
								"PartitionFunctionType": null,
								"Keys": null
							},
							"StorageDescriptor": {
								"Distribution": null,
								"Columns": [
									{
										"Name": "ProductId",
										"Description": "The unique identifier of a Product.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "ProductId"
										}
									},
									{
										"Name": "ProductName",
										"Description": "The name of the Product, which normally corresponds to the 'marketing name' of the Product.",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 256,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "ProductName"
										}
									},
									{
										"Name": "IntroductionDate",
										"Description": "The date that the Product was introduced for sale.",
										"OriginDataTypeName": {
											"TypeName": "date",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"DateFormat": "YYYY-MM-DD",
												"HIVE_TYPE_STRING": "date"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "IntroductionDate"
										}
									},
									{
										"Name": "ActualAbandonmentDate",
										"Description": "The actual date that the marketing of the product was discontinued. \n\nAbandonment is a component in the decline stage of the product's life cycle characterized by a reduced market demand for the product and an increased number of competing products with similar characteristics.\n\nThere are three (3) strategies for abandoning a product:\n\n(1)  Reduced marketing and expenditures to maintain profits.\n\n(2)  Concentrating on the strongest market segments and eliminating the weaker market segments\n\n(3)  Maintain the marketing level until the product is discontinued.",
										"OriginDataTypeName": {
											"TypeName": "date",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"DateFormat": "YYYY-MM-DD",
												"HIVE_TYPE_STRING": "date"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "ActualAbandonmentDate"
										}
									},
									{
										"Name": "ProductGrossWeight",
										"Description": "The gross product weight.",
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 18,
											"Scale": 8,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "ProductGrossWeight"
										}
									},
									{
										"Name": "ItemSku",
										"Description": "The Stock Keeping Unit identifier, which is typically used for inventory-related activities.",
										"OriginDataTypeName": {
											"TypeName": "string",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 40,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "string"
											}
										},
										"BaseAttributeReference": {
											"Entity": "RetailProduct.cdm.json/RetailProduct",
											"Name": "ItemSku"
										}
									},
									{
										"Name": "ListPrice",
										"Description": "The product price.",
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 0,
											"Precision": 18,
											"Scale": 2,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									}
								],
								"ColumnSetEntityName": "2f7522a8-b445-4c51-91f6-970953f00b75",
								"Format": {
									"InputFormat": "org.apache.hadoop.mapred.SequenceFileInputFormat",
									"OutputFormat": "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat",
									"FormatType": "csv",
									"SerializeLib": "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
									"Properties": {
										"path": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/product",
										"delimiter": ",",
										"firstRowAsHeader": "false",
										"multiLine": "false",
										"serialization.format": "1",
										"escape": "\\",
										"quote": "\"",
										"FormatTypeSetToDatabaseDefault": true,
										"header": "false"
									}
								},
								"Source": {
									"Provider": "ADLS",
									"Location": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/product",
									"Properties": {
										"LinkedServiceName": "hallinc-synapse-WorkspaceDefaultStorage",
										"LocationSetToDatabaseDefault": true
									}
								},
								"Properties": {
									"textinputformat.record.delimiter": ",",
									"compression": "{\"type\":\"None\",\"level\":\"optimal\"}",
									"derivedModelAttributeInfo": "{\"attributeReferences\":{\"ProductId\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductId\"},\"ProductName\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductName\"},\"IntroductionDate\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"IntroductionDate\"},\"ActualAbandonmentDate\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ActualAbandonmentDate\"},\"ProductGrossWeight\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductGrossWeight\"},\"ItemSku\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ItemSku\"}}}"
								},
								"Compressed": false,
								"SerDeInfo": null,
								"IsStoredAsSubdirectories": false
							},
							"Owner": null,
							"CreateTime": 0,
							"LastAccessTime": 0,
							"Retention": 0,
							"Temporary": false,
							"IsRewriteEnabled": false,
							"ViewOriginalText": null,
							"ViewExpandedText": null,
							"Origin": {
								"Type": "SPARK"
							},
							"OriginObjectId": null,
							"IsSharedEntity": false,
							"PublishStatus": "PUBLISHED",
							"Properties": {
								"DerivedModelEntityInfo": "{\"entityDirectives\":{\"name\":\"product\",\"description\":\"A product is anything that can be offered to a market that might satisfy a want or need by potential customers.    That product is the sum of all physical, psychological, symbolic, and service attributes associated with it.\\n\\nThere are two basic types of products:\\n\\n- Tangible (physical)\\n- Intangible (non-physical) such as services\\n\\nA service is a non-material or intangible product - such as professional consultancy, maintenance service, repair service etc.\\nEach product has its own benefits, application, brand name, and packaging that gives it its own identity and distinguishing characteristics.\\n\\nEvery business or organization has business rules that define precisely what a product is.    While we intuitively know what a product is, we must quantify that knowledge and associated business rules with consistent definitions that can be implemented within the organization in strategies and applications.\\n\\nA product typically goes through five stages of development:\\n\\n(1) Idea Stage - involving a thorough evaluation of the potential product\\n\\n(2) Concept Stage - determines customer acceptance by testing and presentation to consumers and distribution channel members.   Specific aspects regarding quality, dependability, reliability, warranty, packaging, service, pricing, terms of sale, sales and distribution channels, advertising and promotions are evaluated.\\n\\n(3) Product Development Stage - transforms the prototype product into an actual product for mass sale.   This stage requires close interaction between both marketing and manufacturing.\\n\\n(4) Test Marketing Stage - may or may not be used since it is an expensive and time-consuming process.  Test marketing involves evaluating various product options and alternatives.\\n\\n(5) Commercialization - It is very expensive to launch a new product so commercialization only applies to those specific products that are actually going to be sold to the market.\\n\\nProducts tend to be categorized as either:  Industrial goods and consumer goods\\n\\nIndustrial goods are used to produce other products .\\n\\nIndustrial goods may be further divided into:\\n\\n- Raw materials\\n- Equipment\\n- Pre-built materials \\n- Supplies.\\n\\nConsumer goods are intended for consumption by the general public.\\n\\nConsumer goods may be further divided into:\\n\\n- Durable goods\\n- Nondurable goods\\n- Packaged goods\\n\\nA product may be a member of a product family or product line.\\n\\nA product family is a grouping of products or services that are related to each other by common function, functionality, design platform or similar characteristics.\\n\\nMembers of a product family frequently have many common parts and assemblies.\\n\\nProduct families are the highest level of grouping for forecasting, capacity planning or related functions.\\n\\nEx:\\nThe Apple Macintosh family of products consists of the product lines:\\n- Mac mini\\n- MacBook Pro\\n- Mac Pro\\n\\nA product line is a grouping of products that are closely related in usage, functionality or marketing characteristics.\\n\\nA Product Family typically is created to address one or five functions:\\n\\n1. To increase profits and not erode the sales of existing products\\n\\n2. To attract additional Markets or Market Segments\\n\\n3. To counter competitor's products\\n\\n4. To fill a gap in an existing Product Family.\\n\\n5. To promote sales of other products in the family line\\n\\nLine Depth refers to the number of products in the product line.\\n\\nLine consistency refers to how closely related the products are that make up the product line.\\n\\nLine vulnerability refers to the percentage of sales or profits that are derived from only a few products in the product line.\\n\\nProduct width refers to the number of different product lines sold by a company.\\n\\nProduct mix refers to the total number of products sold in all product lines.\\n\\nLine extension refers to the adding of a new product to a line.\\n\\n\\\"Trading up or brand leveraging\\\" refers to adding a product of better quality to a product line than the other products in that line.\\n\\n\\\"Trading down\\\" refers to adding a product of lesser quality to a product line than the other products in that line.\\n\\nIf a line of products is sold with the same brand name, this is referred to as family branding.\\nStrategy and decisions regarding a product line are usually incorporated in a high-level marketing plan addressing product line strategy, sales, channels, distribution channels, pricing and related issues.\\nA product-line manager is responsible for a product line and supervises several product managers who are responsible for individual products within the line.\\nProduct-line managers typically have the following responsibilities:\\n- Expansion and composition of a product line\\n- Evaluate the effects of product mixes on the profitability of other items in the line\\n- Planning and allocation of resources to individual products in the line\\nA product is normally associated with a brand strategy - manufacturer, private or generic.\\n\\n1. Manufacturer-  or 'national' branding in which the brand is assigned by the manufacturer of the Product.\\n\\n2. Private - or 'dealer' branding in which the brand is assigned by the retailer or wholesaler of the Product.\\n\\n3. Generic - in which the Product is not marked with any identification.   Generic brands are a means for manufacturers to increase profits by saving on advertising, packaging or other costs associated with manufacturer or private branding.\\n\\nA brand is name, term, sign, symbol or design or a combination of these which identify the goods or services and differentiate them from those of competitors'\\n\\nA Trade mark is a brand or some part of the brand that is given legal protection because it is capable of exclusive appropriation and representation.\\n\\nManufacturers can use their own brands (known as Manufacturers' brands) or brands of their distributors (Distributors' brands).\\n\\nManufacturers/ distributors use brand names for a variety of reasons ranging from simple identification purposes to having legal protection for unique features of the products from imitations.\\n\\nBrands help consumers recognize certain quality parameters. In some cases, brands are just used to endow the product with unique story and character which itself can be a basis for product differentiation.\\n\\nIndividual brands have their own identity and the corporate or common name is not used to promote its equity.\\n\\nIndividual branding requires more expensive advertising and brand extensive brand creation investments.  By extension, each new brand does not benefit from the positive perceptions of earlier brands.\\n\\nBy contrast, family branding has several advantages.\\n\\nEach new product is quickly associated with the other products and brand in terms of quality and benefits.\\n\\nReduced or eliminated time for name identification and advertising for name recognition purposes.\",\"baseEntityReference\":{\"name\":\"RetailProduct\",\"path\":\"RetailProduct.cdm.json/RetailProduct\"},\"primaryKey\":[\"ProductId\"],\"projectionInfo\":{\"attributes\":[{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductId\"},\"dataType\":\"long\",\"description\":\"The unique identifier of a Product.\",\"isNullable\":false,\"name\":\"ProductId\"},{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductName\"},\"dataType\":\"string\",\"dataTypeLength\":256,\"description\":\"The name of the Product, which normally corresponds to the 'marketing name' of the Product.\",\"isNullable\":true,\"name\":\"ProductName\"},{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"IntroductionDate\"},\"dataType\":\"date\",\"dateFormat\":\"YYYY-MM-DD\",\"description\":\"The date that the Product was introduced for sale.\",\"isNullable\":true,\"name\":\"IntroductionDate\"},{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ActualAbandonmentDate\"},\"dataType\":\"date\",\"dateFormat\":\"YYYY-MM-DD\",\"description\":\"The actual date that the marketing of the product was discontinued. \\n\\nAbandonment is a component in the decline stage of the product's life cycle characterized by a reduced market demand for the product and an increased number of competing products with similar characteristics.\\n\\nThere are three (3) strategies for abandoning a product:\\n\\n(1)  Reduced marketing and expenditures to maintain profits.\\n\\n(2)  Concentrating on the strongest market segments and eliminating the weaker market segments\\n\\n(3)  Maintain the marketing level until the product is discontinued.\",\"isNullable\":true,\"name\":\"ActualAbandonmentDate\"},{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ProductGrossWeight\"},\"dataType\":\"decimal\",\"dataTypeLength\":18,\"description\":\"The gross product weight.\",\"isNullable\":true,\"scale\":8,\"name\":\"ProductGrossWeight\"},{\"type\":\"Existing\",\"attributeReference\":{\"entity\":\"RetailProduct.cdm.json/RetailProduct\",\"name\":\"ItemSku\"},\"dataType\":\"string\",\"dataTypeLength\":40,\"description\":\"The Stock Keeping Unit identifier, which is typically used for inventory-related activities.\",\"isNullable\":true,\"name\":\"ItemSku\"},{\"type\":\"New\",\"dataType\":\"decimal\",\"dataTypeLength\":18,\"description\":\"The product price.\",\"isNullable\":false,\"scale\":2,\"name\":\"ListPrice\"}]}}}",
								"Description": "A product is anything that can be offered to a market that might satisfy a want or need by potential customers.    That product is the sum of all physical, psychological, symbolic, and service attributes associated with it.\n\nThere are two basic types of products:\n\n- Tangible (physical)\n- Intangible (non-physical) such as services\n\nA service is a non-material or intangible product - such as professional consultancy, maintenance service, repair service etc.\nEach product has its own benefits, application, brand name, and packaging that gives it its own identity and distinguishing characteristics.\n\nEvery business or organization has business rules that define precisely what a product is.    While we intuitively know what a product is, we must quantify that knowledge and associated business rules with consistent definitions that can be implemented within the organization in strategies and applications.\n\nA product typically goes through five stages of development:\n\n(1) Idea Stage - involving a thorough evaluation of the potential product\n\n(2) Concept Stage - determines customer acceptance by testing and presentation to consumers and distribution channel members.   Specific aspects regarding quality, dependability, reliability, warranty, packaging, service, pricing, terms of sale, sales and distribution channels, advertising and promotions are evaluated.\n\n(3) Product Development Stage - transforms the prototype product into an actual product for mass sale.   This stage requires close interaction between both marketing and manufacturing.\n\n(4) Test Marketing Stage - may or may not be used since it is an expensive and time-consuming process.  Test marketing involves evaluating various product options and alternatives.\n\n(5) Commercialization - It is very expensive to launch a new product so commercialization only applies to those specific products that are actually going to be sold to the market.\n\nProducts tend to be categorized as either:  Industrial goods and consumer goods\n\nIndustrial goods are used to produce other products .\n\nIndustrial goods may be further divided into:\n\n- Raw materials\n- Equipment\n- Pre-built materials \n- Supplies.\n\nConsumer goods are intended for consumption by the general public.\n\nConsumer goods may be further divided into:\n\n- Durable goods\n- Nondurable goods\n- Packaged goods\n\nA product may be a member of a product family or product line.\n\nA product family is a grouping of products or services that are related to each other by common function, functionality, design platform or similar characteristics.\n\nMembers of a product family frequently have many common parts and assemblies.\n\nProduct families are the highest level of grouping for forecasting, capacity planning or related functions.\n\nEx:\nThe Apple Macintosh family of products consists of the product lines:\n- Mac mini\n- MacBook Pro\n- Mac Pro\n\nA product line is a grouping of products that are closely related in usage, functionality or marketing characteristics.\n\nA Product Family typically is created to address one or five functions:\n\n1. To increase profits and not erode the sales of existing products\n\n2. To attract additional Markets or Market Segments\n\n3. To counter competitor's products\n\n4. To fill a gap in an existing Product Family.\n\n5. To promote sales of other products in the family line\n\nLine Depth refers to the number of products in the product line.\n\nLine consistency refers to how closely related the products are that make up the product line.\n\nLine vulnerability refers to the percentage of sales or profits that are derived from only a few products in the product line.\n\nProduct width refers to the number of different product lines sold by a company.\n\nProduct mix refers to the total number of products sold in all product lines.\n\nLine extension refers to the adding of a new product to a line.\n\n\"Trading up or brand leveraging\" refers to adding a product of better quality to a product line than the other products in that line.\n\n\"Trading down\" refers to adding a product of lesser quality to a product line than the other products in that line.\n\nIf a line of products is sold with the same brand name, this is referred to as family branding.\nStrategy and decisions regarding a product line are usually incorporated in a high-level marketing plan addressing product line strategy, sales, channels, distribution channels, pricing and related issues.\nA product-line manager is responsible for a product line and supervises several product managers who are responsible for individual products within the line.\nProduct-line managers typically have the following responsibilities:\n- Expansion and composition of a product line\n- Evaluate the effects of product mixes on the profitability of other items in the line\n- Planning and allocation of resources to individual products in the line\nA product is normally associated with a brand strategy - manufacturer, private or generic.\n\n1. Manufacturer-  or 'national' branding in which the brand is assigned by the manufacturer of the Product.\n\n2. Private - or 'dealer' branding in which the brand is assigned by the retailer or wholesaler of the Product.\n\n3. Generic - in which the Product is not marked with any identification.   Generic brands are a means for manufacturers to increase profits by saving on advertising, packaging or other costs associated with manufacturer or private branding.\n\nA brand is name, term, sign, symbol or design or a combination of these which identify the goods or services and differentiate them from those of competitors'\n\nA Trade mark is a brand or some part of the brand that is given legal protection because it is capable of exclusive appropriation and representation.\n\nManufacturers can use their own brands (known as Manufacturers' brands) or brands of their distributors (Distributors' brands).\n\nManufacturers/ distributors use brand names for a variety of reasons ranging from simple identification purposes to having legal protection for unique features of the products from imitations.\n\nBrands help consumers recognize certain quality parameters. In some cases, brands are just used to endow the product with unique story and character which itself can be a basis for product differentiation.\n\nIndividual brands have their own identity and the corporate or common name is not used to promote its equity.\n\nIndividual branding requires more expensive advertising and brand extensive brand creation investments.  By extension, each new brand does not benefit from the positive perceptions of earlier brands.\n\nBy contrast, family branding has several advantages.\n\nEach new product is quickly associated with the other products and brand in terms of quality and benefits.\n\nReduced or eliminated time for name identification and advertising for name recognition purposes.",
								"DisplayFolderInfo": "{\"name\":\"Product\",\"colorCode\":\"#BD4B37\"}",
								"PrimaryKeys": "ProductId",
								"spark.sql.sources.provider": "csv",
								"spark.sql.sources.schema.numParts": "1",
								"spark.sql.sources.schema.part.0": "{\"type\":\"struct\",\"fields\":[{\"name\":\"ProductId\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"ProductName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"IntroductionDate\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ActualAbandonmentDate\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ProductGrossWeight\",\"type\":\"decimal(18,8)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ItemSku\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ListPrice\",\"type\":\"decimal(18,2)\",\"nullable\":false,\"metadata\":{}}]}"
							},
							"ObjectVersion": 1,
							"ObjectId": "898a5c72-810d-48bd-8834-6ca26191f5a9",
							"Description": "A product is anything that can be offered to a market that might satisfy a want or need by potential customers.    That product is the sum of all physical, psychological, symbolic, and service attributes associated with it.\n\nThere are two basic types of products:\n\n- Tangible (physical)\n- Intangible (non-physical) such as services\n\nA service is a non-material or intangible product - such as professional consultancy, maintenance service, repair service etc.\nEach product has its own benefits, application, brand name, and packaging that gives it its own identity and distinguishing characteristics.\n\nEvery business or organization has business rules that define precisely what a product is.    While we intuitively know what a product is, we must quantify that knowledge and associated business rules with consistent definitions that can be implemented within the organization in strategies and applications.\n\nA product typically goes through five stages of development:\n\n(1) Idea Stage - involving a thorough evaluation of the potential product\n\n(2) Concept Stage - determines customer acceptance by testing and presentation to consumers and distribution channel members.   Specific aspects regarding quality, dependability, reliability, warranty, packaging, service, pricing, terms of sale, sales and distribution channels, advertising and promotions are evaluated.\n\n(3) Product Development Stage - transforms the prototype product into an actual product for mass sale.   This stage requires close interaction between both marketing and manufacturing.\n\n(4) Test Marketing Stage - may or may not be used since it is an expensive and time-consuming process.  Test marketing involves evaluating various product options and alternatives.\n\n(5) Commercialization - It is very expensive to launch a new product so commercialization only applies to those specific products that are actually going to be sold to the market.\n\nProducts tend to be categorized as either:  Industrial goods and consumer goods\n\nIndustrial goods are used to produce other products .\n\nIndustrial goods may be further divided into:\n\n- Raw materials\n- Equipment\n- Pre-built materials \n- Supplies.\n\nConsumer goods are intended for consumption by the general public.\n\nConsumer goods may be further divided into:\n\n- Durable goods\n- Nondurable goods\n- Packaged goods\n\nA product may be a member of a product family or product line.\n\nA product family is a grouping of products or services that are related to each other by common function, functionality, design platform or similar characteristics.\n\nMembers of a product family frequently have many common parts and assemblies.\n\nProduct families are the highest level of grouping for forecasting, capacity planning or related functions.\n\nEx:\nThe Apple Macintosh family of products consists of the product lines:\n- Mac mini\n- MacBook Pro\n- Mac Pro\n\nA product line is a grouping of products that are closely related in usage, functionality or marketing characteristics.\n\nA Product Family typically is created to address one or five functions:\n\n1. To increase profits and not erode the sales of existing products\n\n2. To attract additional Markets or Market Segments\n\n3. To counter competitor's products\n\n4. To fill a gap in an existing Product Family.\n\n5. To promote sales of other products in the family line\n\nLine Depth refers to the number of products in the product line.\n\nLine consistency refers to how closely related the products are that make up the product line.\n\nLine vulnerability refers to the percentage of sales or profits that are derived from only a few products in the product line.\n\nProduct width refers to the number of different product lines sold by a company.\n\nProduct mix refers to the total number of products sold in all product lines.\n\nLine extension refers to the adding of a new product to a line.\n\n\"Trading up or brand leveraging\" refers to adding a product of better quality to a product line than the other products in that line.\n\n\"Trading down\" refers to adding a product of lesser quality to a product line than the other products in that line.\n\nIf a line of products is sold with the same brand name, this is referred to as family branding.\nStrategy and decisions regarding a product line are usually incorporated in a high-level marketing plan addressing product line strategy, sales, channels, distribution channels, pricing and related issues.\nA product-line manager is responsible for a product line and supervises several product managers who are responsible for individual products within the line.\nProduct-line managers typically have the following responsibilities:\n- Expansion and composition of a product line\n- Evaluate the effects of product mixes on the profitability of other items in the line\n- Planning and allocation of resources to individual products in the line\nA product is normally associated with a brand strategy - manufacturer, private or generic.\n\n1. Manufacturer-  or 'national' branding in which the brand is assigned by the manufacturer of the Product.\n\n2. Private - or 'dealer' branding in which the brand is assigned by the retailer or wholesaler of the Product.\n\n3. Generic - in which the Product is not marked with any identification.   Generic brands are a means for manufacturers to increase profits by saving on advertising, packaging or other costs associated with manufacturer or private branding.\n\nA brand is name, term, sign, symbol or design or a combination of these which identify the goods or services and differentiate them from those of competitors'\n\nA Trade mark is a brand or some part of the brand that is given legal protection because it is capable of exclusive appropriation and representation.\n\nManufacturers can use their own brands (known as Manufacturers' brands) or brands of their distributors (Distributors' brands).\n\nManufacturers/ distributors use brand names for a variety of reasons ranging from simple identification purposes to having legal protection for unique features of the products from imitations.\n\nBrands help consumers recognize certain quality parameters. In some cases, brands are just used to endow the product with unique story and character which itself can be a basis for product differentiation.\n\nIndividual brands have their own identity and the corporate or common name is not used to promote its equity.\n\nIndividual branding requires more expensive advertising and brand extensive brand creation investments.  By extension, each new brand does not benefit from the positive perceptions of earlier brands.\n\nBy contrast, family branding has several advantages.\n\nEach new product is quickly associated with the other products and brand in terms of quality and benefits.\n\nReduced or eliminated time for name identification and advertising for name recognition purposes."
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "salesorder",
							"EntityType": "TABLE",
							"TableType": "EXTERNAL",
							"Namespace": {
								"SchemaName": null,
								"DatabaseName": "retaildb",
								"DatabaseId": null
							},
							"Partitioning": {
								"PartitionFunctionType": null,
								"Keys": null
							},
							"StorageDescriptor": {
								"Distribution": null,
								"Columns": [
									{
										"Name": "SalesOrderId",
										"Description": "The unique identifier of an order.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									},
									{
										"Name": "OrderDate",
										"Description": "The date of the order.",
										"OriginDataTypeName": {
											"TypeName": "timestamp",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"TimestampFormat": "yyyy/MM/dd",
												"HIVE_TYPE_STRING": "timestamp"
											}
										}
									},
									{
										"Name": "LineItemId",
										"Description": "The ID of an individual line item.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": false,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									},
									{
										"Name": "CustomerId",
										"Description": "The customer.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									},
									{
										"Name": "ProductId",
										"Description": "The product.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									},
									{
										"Name": "Quantity",
										"Description": "The order quantity.",
										"OriginDataTypeName": {
											"TypeName": "long",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "long"
											}
										}
									}
								],
								"ColumnSetEntityName": "17424a7f-2f10-45b6-9a07-d35de4733da5",
								"Format": {
									"InputFormat": "org.apache.hadoop.mapred.SequenceFileInputFormat",
									"OutputFormat": "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat",
									"FormatType": "csv",
									"SerializeLib": "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
									"Properties": {
										"path": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/salesorder",
										"delimiter": ",",
										"firstRowAsHeader": "false",
										"multiLine": "false",
										"serialization.format": "1",
										"FormatTypeSetToDatabaseDefault": false,
										"header": "false"
									}
								},
								"Source": {
									"Provider": "ADLS",
									"Location": "abfss://hallinc@hallincdatalake.dfs.core.windows.net/retaildb/salesorder",
									"Properties": {
										"LinkedServiceName": "hallinc-synapse-WorkspaceDefaultStorage",
										"LocationSetToDatabaseDefault": false
									}
								},
								"Properties": {
									"textinputformat.record.delimiter": ",",
									"compression": "",
									"derivedModelAttributeInfo": "{\"attributeReferences\":{}}"
								},
								"Compressed": false,
								"SerDeInfo": null,
								"IsStoredAsSubdirectories": false
							},
							"Owner": null,
							"CreateTime": 0,
							"LastAccessTime": 0,
							"Retention": 0,
							"Temporary": false,
							"IsRewriteEnabled": false,
							"ViewOriginalText": null,
							"ViewExpandedText": null,
							"Origin": {
								"Type": "SPARK"
							},
							"OriginObjectId": null,
							"IsSharedEntity": false,
							"PublishStatus": "PUBLISHED",
							"Properties": {
								"Description": "",
								"DisplayFolderInfo": "{\"name\":\"Others\",\"colorCode\":\"\"}",
								"PrimaryKeys": "SalesOrderId,LineItemId",
								"spark.sql.sources.provider": "csv",
								"spark.sql.sources.schema.numParts": "1",
								"spark.sql.sources.schema.part.0": "{\"type\":\"struct\",\"fields\":[{\"name\":\"SalesOrderId\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"OrderDate\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"LineItemId\",\"type\":\"long\",\"nullable\":false,\"metadata\":{}},{\"name\":\"CustomerId\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ProductId\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Quantity\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}"
							},
							"ObjectVersion": 1,
							"ObjectId": "3c06c913-54f5-4724-b851-6e00023cebf6",
							"Description": ""
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "relationship-fqvjibzxvw",
							"EntityType": "RELATIONSHIP",
							"Namespace": {
								"DatabaseName": "retaildb"
							},
							"Origin": {
								"Type": "SPARK"
							},
							"FromTableName": "product",
							"ToTableName": "salesorder",
							"ColumnRelationshipInformations": [
								{
									"FromColumnName": "ProductId",
									"ToColumnName": "ProductId"
								}
							],
							"RelationshipType": 0,
							"PublishStatus": "PUBLISHED",
							"ObjectVersion": 1,
							"ObjectId": "01a84449-3fc3-488a-a1cf-ab23cceda611",
							"Properties": {}
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "relationship-tqvqoiqwdh",
							"EntityType": "RELATIONSHIP",
							"Namespace": {
								"DatabaseName": "retaildb"
							},
							"Origin": {
								"Type": "SPARK"
							},
							"FromTableName": "customer",
							"ToTableName": "salesorder",
							"ColumnRelationshipInformations": [
								{
									"FromColumnName": "CustomerId",
									"ToColumnName": "CustomerId"
								}
							],
							"RelationshipType": 0,
							"PublishStatus": "PUBLISHED",
							"ObjectVersion": 1,
							"ObjectId": "4eb83c25-1896-444a-9341-1d7280e3a1f3",
							"Properties": {}
						},
						"Source": {
							"Type": "SPARK"
						}
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/hallincspark')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 10
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 0,
					"minNodeCount": 0
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "swedencentral"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-custstgacct--hallinc-synapse-hallincdatalake')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Storage/storageAccounts/hallincdatalake",
				"groupId": "dfs",
				"fqdns": [
					"hallincdatalake.dfs.core.windows.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sql--hallinc-synapse')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse",
				"groupId": "sql",
				"fqdns": [
					"hallinc-synapse.e6ccbef2-9136-4d19-886a-6c98a1efff49.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sqlOnDemand--hallinc-synapse')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/a011ea95-c1fe-4125-9cef-82abcac7f740/resourceGroups/hallinc-rg/providers/Microsoft.Synapse/workspaces/hallinc-synapse",
				"groupId": "sqlOnDemand",
				"fqdns": [
					"hallinc-synapse-ondemand.e6ccbef2-9136-4d19-886a-6c98a1efff49.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		}
	]
}